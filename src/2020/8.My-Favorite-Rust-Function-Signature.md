>* My Favorite Rust Function Signature 译文
>* 原文链接：https://www.brandonsmith.ninja/blog/favorite-rust-function
>* 原文作者：[Brandon Smith](https://github.com/brundonsmith)
>* 译文来自：https://github.com/suhanyujie/article-transfer-rs/
>* 译者：[suhanyujie](https://github.com/suhanyujie)
>* 译者博客：[suhanyujie](https://ishenghuo.cnblogs.com/)
>* ps：水平有限，翻译不当之处，还请指正。
>* 标签：Rust，解析器

# My Favorite Rust Function Signature
I've gotten really into writing parsers lately, and Rust has turned out to be the perfect language for that. In the course of my adventures, I came up with the following:
最近，我对写解析器很感兴趣，而 Rust 已被证明是最适合写解析器的语言。在我冒险的过程中，我想到了以下几点：

```
fn tokenize<'a>(code: &'a str) -> impl Iterator<Item=&'a str> {
  ...
}
```

这真的加深了我对 Rust 的热爱。

## 这个函数是干什么用的？

For those not familiar with parsing, tokenization is the first step of the process. It takes a raw code string, like this:
对于那些不熟悉解析器的人来讲，token 化是解析器的第一步。它需要一个原始字符串作为输入，类似于这样：

```rust
let a = "foo";
```

并将其转化为一些列有意义的符号，比如下面这样：

```
["let", "a", "=", "\"foo\"", ";"]
```

This phase isn't terribly complicated, but it simplifies the mental model for the next pass: constructing an "abstract syntax tree". It removes whitespace from the equation, bundles up segments like strings and numbers, and just generally makes the code in the next pass cleaner.
>这个阶段并不复杂，但它简化了下一个阶段的思维模型：构建一个“抽象语法树”。它移除了源字符串中等式两边的空白符，将字符串和数字之类的段捆绑起来，并使下一步的代码更简洁。

The downside is that, if you perform this as a separate pass, your parser now has to iterate over all of the source code twice. This may not be the end of the world: tokenizing isn't the most expensive operation. But it isn't ideal, so some parsers combine the two passes into a single one, saving cycles at the expense of readability.
>如果你单独执行此操作，缺点是，你的解析器现在必须遍历所有源代码两次。这可能不是最糟糕的：token 化并不是开销最大的操作。但这并不理想，因此一些解析器将两次传递合而为一，以牺牲可读性为代价优化了性能。

## Rust 版本的解析器是什么样的？

我在这里再拷贝一次函数签名作为引用：

```
fn tokenize<'a>(code: &'a str) -> impl Iterator<Item=&'a str> {
  ...
}
```

There are several things going on here.
这里有一些操作。

`&str`, in Rust, is a "string slice". It's effectively a character pointer and a length. The contents of the slice are guaranteed to be in valid, alive memory. `&'a str` is a string slice with a lifetime. The lifetime `'a`, to be exact. This lifetime describes a limited span of time in which the reference (and the full contents of the slice) are guaranteed to be in valid, alive memory. More on this later.
>在 Rust 中，`&str` 是一个“字符串切片”。它的本质是一个字符指针加长度。切片的内容保证是在有效的内存中的。`&'a str` 是一个具有生命周期的字符串切片。`'a` 代表了具体的生命周期。这里的生命周期描述了保证在一段时间内，保证该内存片段是合法的，在有效的活内存中。稍后会对此进行更多介绍。

`Iterator<Item=&'a str>` is an iterator over elements of type `&'a str`. This is a trait, though, not a concrete type. Rust needs a concrete type with a fixed size when you're defining something like a function, but luckily we can say `impl Iterator<Item=&'a str>`, which tells Rust, "fill in some type that implements `Iterator<Item=&'a str>`, to be inferred at compile-time". This is very helpful because in Rust there are lots and lots of different concrete types for `Iterator`; applying something like a `map()` or a `filter()` returns a whole new concrete type. So this way, we don't have to worry about keeping the function signature up to date as we work on the logic.
>`Iterator<Item=&'a str>` 是 `&'a str` 类型的元素迭代器。不过，它也是一个 trait，而非具体类型。Rust 中，在定义函数时，通常其参数需要是能确定大小的具体类型，但幸运的是，我们可以使用 `impl Iterator<Item=&'a str>`，这在编译推断时，告诉 Rust 编译器，“这个类型实现了 `Iterator<Item=&'a str>`”。这是非常有用的，因为在 Rust 中有很多很多不同的 `Iterator` 的具体类型；基于它可以调用 `map()` 或者 `filter()` 之类的函数，然后返回一个全新的具体类型。这样，我们就不用担心，在处理逻辑时要保持函数签名是最新的。

## 有什么优点？
Okay, so we have a function that takes a reference to a string slice and returns an iterator over string slices. Why's that special? There are two reasons.
>好了，现在我们有一个函数，它接收一个字符切片引用作为参数，并返回一个字符串切片迭代器。这有什么特别的呢？主要有以下两点原因。

### Iterators let you treat one pass like it's two 
>迭代器可以允许你讲一次传递当做两次

Remember how I said you traditionally have to pick between doing a separate tokenization pass, and doing a single pass with all the logic interleaved? With an iterator, you can have the best of both worlds.

When this function completes, it hasn't yet iterated over the string. It hasn't allocated any kind of collection in memory. It returns a structure that's prepared to iterate over the input string slice and produce a sequence of new slices. When this value later gets `map()`ed into something else, or `filter()`ed, or any other `Iterator` transformations get applied, the stages of the process get interleaved, and the "loops" effectively get folded into a single one. By doing this, we're able to get the clean abstraction of a tokenizing "pass" without the runtime overhead of a second loop!

But other languages have iterators. Rust's may be extra powerful and ergonomic, but they aren't a totally unique feature. The next part is very much unique to Rust.

### Lifetimes let you share references fearlessly 
The `tokenize()` function doesn't allocate any new memory for a collection of tokens. That's great. But what may be less obvious is that it also doesn't allocate any memory for the tokens themselves! Each string slice representing a token is a _direct pointer to part of the original string_.

You can do this in C/C++, of course, but there's a danger: if those tokens are ever accessed after the original code string has been freed, you'll have a memory error.

For example: let's say you open a file and load the source code from it, and store the result in a local variable. Then you `tokenize()` it and send the tokens on to somewhere else outside of the function where the original string lived. Voilà, you've got a [use-after-free error](https://en.wikipedia.org/wiki/Dangling_pointer).

One way to guard against this is by copying each string segment into a new string, allocated on the heap, which allows you to safely pass it on after the original string is gone. But this comes with a cost: creating, copying, and eventually disposing of each of those new strings takes time (and memory). Code down the line also has to be aware that it's responsible for de-allocating those strings, otherwise they'll leak.

This is where the magic of lifetimes comes into play.

Rust prevents the above situation entirely. Normally, though, to accomplish this a `&str` coming into a function from elsewhere must be assumed to be static, or to be alive for the entire duration of the program's execution. This is the status assigned to, for example, a string literal that you've manually entered into your Rust code. Rust doesn't know, in the context of the function, how long that reference will be valid, so it must be pessimistic.

**But**. That little `'a` says: "these things all live for the same span of time". We can assert that the original source code string lives at least as long as the tokens that reference it. By doing so, Rust can reason about whether or not those resulting token references are valid at a given point, and therefore doesn't have to assume them to be static! We can do whatever we want with those tokens and the compiler will guarantee that they always point to something valid, even if the source code is loaded in dynamically at runtime (from a file or otherwise). If we find out later via a compiler error that they really do need to outlive the source string, then we can copy them ("take ownership") at that point. If the compiler doesn't force us to do so, we know we're safe, and we know we can continue using the most efficient possible approach, fearlessly.

What we've effectively done is written the most optimistic possible function (in terms of memory safety), with no downsides, because the Rust compiler will tell us if we're misusing it and force us to then "step down" to whatever level of extra accommodation is needed.

## Conclusion 

I've been using (and loving) Rust for about a year and a half now. And there are many things to love, but when I got this function working I immediately saw it as a microcosm of what really sets the language apart. This is something that you **cannot do** both a) this safely and b) this efficiently **in any other language**. This is the power of Rust.
